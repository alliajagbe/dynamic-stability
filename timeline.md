# Timeline

### Weeks 1-2: Focused Literature Review
- *Objective*: Identify key methodologies, challenges, and advancements in dynamic stabilization and reinforcement learning (RL).
- *Actions*:
  - [x] Conduct a systematic review of recent papers and seminal works on RL algorithms (e.g., Q-learning, PPO) and their application to dynamic stabilization.
  - [x] Review case studies and benchmarking studies on dynamic stabilization tasks.
  - [x] Identify gaps in the current research landscape and opportunities for innovation.

### Weeks 3-4: Development of Reinforcement Learning Models
- *Objective*: Develop initial RL models targeting basic dynamic stabilization tasks within the OpenAI Gym environment.
- *Actions*:
  - [x] Implement baseline models using classic RL algorithms, starting with Q-learning.
  - [x] Explore the implementation of advanced algorithms like PPO, comparing their theoretical advantages.
  - [ ] Utilize the OpenAI Gym environment to simulate basic stabilization tasks, adjusting model parameters for initial testing.

### Weeks 5-6: Model Development and Preliminary Testing
- *Objective*: Enhance the RL models for better performance and conduct preliminary tests.
- *Actions*:
  - [ ] Refine models based on initial test results, incorporating advanced techniques and algorithms for improved learning efficiency.
  - [ ] Begin using Weights & Biases (Wandb) for tracking experiments, comparing model performances, and logging initial results.
  - [ ] Start preliminary testing to assess model performance against basic stabilization tasks, identifying areas for improvement.

### Weeks 7-8: In-depth Testing, Evaluation, and Optimization
- *Objective*: Conduct comprehensive testing and evaluation, focusing on optimization and robustness.
- *Actions*:
  - [ ] Compare the performance of various algorithms (Q-learning, PPO, etc.) using predefined metrics for stability, efficiency, and adaptability.
  - [ ] Optimize models based on testing feedback, focusing on improving robustness and generalization across different dynamic stabilization tasks.
  - [ ] Utilize Wandb extensively for experiment tracking, result comparison, and identifying best-performing models.

### Weeks 9-10: Extensive Testing, Simulation, and Documentation
- *Objective*: Finalize the testing phase with extensive evaluations and prepare detailed documentation of outcomes.
- *Actions*:
  - [ ] Develop and run simulations to test the models under a wider range of conditions, ensuring robustness and adaptability.
  - [ ] Conduct final evaluations, comparing the models against all predefined metrics and documenting the efficiency of different algorithms.
  - [ ] Compile comprehensive documentation covering the development process, model performances, best practices, and key learnings.
