# Timeline: Empirical Evaluation and Comparison of Reinforcement Learning Algorithms

### Weeks 1-2: Selection and Literature Review
  - [x] We will run multiple algorithms(Qlearning,Deep QNetwork,Proximal Policy Optimization (PPO), etc) suitable for dynamic stabilization from the provided list or additional credible sources. 
  - [x] Conducting a thorough literature review on existing databases around RL modules used for stabilization. 
  - [x] Finally all three of us will identify 1-2 illustrative scenarios for subsequent comparative evaluation.

### Weeks 3-4: Implementation Setup
  - [x] We will then set up a development environment with the necessary tools and libraries for reinforcement learning. Beginning the development and coding of these algorithms, starting with model-free methods due to their typically straightforward implementation.
  - [x] Explore the implementation of advanced algorithms like PPO,QLearning etc, comparing their theoretical advantages.
  - [ ] All of us plan to utilize the OpenAI Gym environment to simulate basic stabilization tasks, fine-tuning the algorithms to achieve the expected performance.

### Weeks 5-6: Model Development and Preliminary Testing
  - [ ] We will define evaluation metrics such as convergence speed, stability, and adaptability to ensure a fair comparison.
  - [ ] We plan to use Weights & Biases (Wandb) for tracking experiments, comparing model performances, and logging initial results.
  - [ ] Start preliminary testing to assess model performance against basic stabilization tasks, identifying areas for improvement.

### Weeks 7-8: In-depth Testing, Evaluation, and Optimization
  - [ ] Compare the performance of various algorithms (Q-learning, PPO, etc.) using predefined metrics for stability, efficiency, and adaptability.
  - [ ] Optimize models based on testing feedback, focusing on improving robustness and generalization across different dynamic stabilization tasks.
  - [ ] Utilize Wandb extensively for experiment tracking, result comparison, and identifying best-performing models.

### Weeks 9-10: Extensive Testing, Simulation, and Documentation
  - [ ] Develop and run simulations to test the models under a wider range of conditions, ensuring robustness and adaptability.
  - [ ] Conduct final evaluations, comparing the models against all predefined metrics and documenting the efficiency of different algorithms.
  - [ ] We will document our comprehensive methodology, results, and insights, culminating in a detailed report that encapsulates our findings and contributions to dynamic stability in robotic systems.
